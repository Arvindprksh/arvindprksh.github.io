---
layout: post
title: Recent Trends in Deep Learning Based Natural Language Processing. Young et al. arXiv. 2018.
subtitle: Title of paper - Recent Trends in Deep Learning Based Natural Language Processing. Young et al. arXiv. 2018.
category: NLP papers - Survey
tags: [neural network, nlp]
permalink: /2019/08/06/Recent_Trends_in_Deep_Learning_Based_Natural_Language_Processing/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This is a brief summary of paper for me to study it and organize the material, [Recent Trends in Deep Learning Based Natural Language Processing. Young et al. arXiv 2018](https://arxiv.org/abs/1708.02709). 

{% include MathJax.html %}

This paper review significant deep learning related models and methods that have been employed for numerous NLP task. 

The section comprised of this paper is as follows: 

- Distributed Representation 

  a. Word Embedding 

  b. Word2vec

  c. character Embeddings

  d. Contextualized Word Embeddings

- Convolutional neural networks

  a. Basic CNN
  
  b. Applications
  
- Recurrent Neural Networks

  a. Nedd for Recurrent Networks
  
  b. RNN Models
  
  c. Applications
  
  d. Attention mechanism
  
  e. Parallelized Attetion: The transformer
  
- Recusive Neural Networks

  a. Basic model
  
  b. Applications
  
- Deep Reinforced Models and Deep unsupervised learning

  a. Reinforcement Learning for sequence generation
  
  b. Unsupervised sentene representation Learning
  
  c. Deep Generative models
  
- Memory-augmented Networks

- Performance of different Models on different NLP tasks

  a. POS tagging
  
  b. parsing
  
  c. Named-Entity Recognition
  
  d. Semantic Role Labeling 
  
  e. Sentiment Classification 
  
  f. Machine Translation 
  
  g. question Answering 
  
  h. Dialogue Systems
  
  i. Contextual Embeddings


<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>
Deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.
</div>
    
<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://arxiv.org/abs/1708.02709">The paper: Recent Trends in Deep Learning Based Natural Language Processing. Young et al. arXiv 2018</a>
</div>

# Reference 

- Paper 
  - [arXiv Version: Recent Trends in Deep Learning Based Natural Language Processing. Young et al. arXiv 2018](https://arxiv.org/abs/1708.02709)
   
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)

