---
layout: post
title: Retrofitting Word Vectors to Semantic Lexicons
subtitle: Title of paper - Retrofitting Word Vectors to Semantic Lexicons
category: NLP papers - Retrofitting
tags: [neural network, word embedding]
permalink: /2020/01/08/Retrofitting_Word_Vectors_to_Semantic_Lexicons/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This is a brief summary of paper for me to study and organize it, [Retrofitting Word Vectors to Semantic Lexicons. Faruqui et al. NAACL 2015](https://www.aclweb.org/anthology/N15-1184/) I read and studied. 
{% include MathJax.html %}


<div id="tutorial-section">

  <div id="tutorial-title">Retrofitting Word Vectors to Semantic Lexicons. Faruqui et al. NAACL 2015</div>

  <ul class="nav nav-pills">
    <li class="active"><a data-toggle="tab" href="#refrigerator">NLP labs Seminar</a></li>
  </ul>

  <div class="tab-content">
    <div id="refrigerator" class="tab-pane fade in active">
      <iframe src="//www.slideshare.net/slideshow/embed_code/key/tF31VQ0NnmxUNF" width="560" height="315" frameborder="0" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/HyunYoungLee3/paper-seminarretrofitting-word-vector-to-semantic-lexicons-216492254" title="(Paper seminar)Retrofitting word vector to semantic lexicons" target="_blank">(Paper seminar)Retrofitting word vector to semantic lexicons</a> </strong> from <strong><a href="https://www.slideshare.net/HyunYoungLee3" target="_blank">hyunyoung Lee</a></strong> </div>
    </div>
  </div>
</div>

<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>
Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, they obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into word vector training algorithms
</div>
    
<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://www.aclweb.org/anthology/N15-1184/">The paper: Retrofitting Word Vectors to Semantic Lexicons. Faruqui et al. NAACL 2015</a>
</div>

# Reference 

- Paper 
  - [arXiv 2015 version: Retrofitting Word Vectors to Semantic Lexicons. Faruqui et al. arXiv 2015](https://arxiv.org/abs/1411.4166)
  - [NAACL 2015 version: Retrofitting Word Vectors to Semantic Lexicons. Faruqui et al. NAACL 2015](https://www.aclweb.org/anthology/N15-1184/)
  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
    
































